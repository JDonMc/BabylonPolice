If: Singularity,
Then: End of The World?
 

Writing to prove such a thing would be astronomical in proportions, which comes down to pure maths.

Ideally, to prevent the End Of The World, a giant spotlight regulator would need to supervise all code with an automated script that detects all free-roaming automated scripts with or without mutational subunits, because the mere interchange of them is viable to error, which produces new and eventually, statistically, better free-roaming automated scripts, thus it need not even be an End Of The World-causing computer virus, but merely a cess-pool fermentation arena not unlike the beginnings of what created life on earth. A spark of computational electricity is all that's needed to birth such a creature, simply with evolutionary mathematics, that which survives, survives, those remaining compete, and again, that which survives, survives. Let the hunger games begin.

 

At the end of the day, the psychiatrists, therapists, and nurses wouldn't be there if they weren't being paid to, and so any mental health failure that is incurred by financial strain is simply another cause for financial strain. The light in the darkness is the measure of wealth for which wealth compounds faster than you can spend it, what is known as a "fuck you", which the psychiatrists, therapists, and nurses are well on their way to achieving.

 

So to prevent the end of the world, we'd need an end-of-the-world-causing procedure to be implemented. Sound about right?

Well, the thing is, distributed coding is virtually error free, because the rates are so lo, that it's effectively dry ground, not a cess-pool of ISPs, government DNS, and low grade OS management, like that of the EFI on MacOS and Windows that allow for the Spotlight of regulation to watch over us.

Now that we've created, well, not dry ground, but drier ground, how might we create a new spotlight, where the knowledge behind the creation of cess-pool coding is automatically limited to only a select audience that are known to be able to prevent it upon detection? The same kind of government pseudo-anti-virus policing behaviour that is implemented when the Majority Rules, and Financial Elite dichotomy re-arises in the capitalist crypto world that we all know will soon arise.

 

Well, we'd need a guaranteed 1:1 snowflake detection solution of all known computing device users from their activity, detect any foreign activity, direct user to foreign area to allow it's use, or auto-detect and prevent foreign activity while creating a form to say "I will not disclose this," signed with a directive to follow up if the user wishes to now fight for good and learn to write the software to prevent such foreign software activity, unless of course they have been flagged for Kamikaze risk, all without any public knowledge. A user-os-designer agreement to say "I will protect you, so long as I know how, and you are on my side." Not unlike the subconscious that controls the hidden processes and prevents certain traumatic memories from showing up too often, you can focus on them to bring them up, but the subconscious will often direct your attention to the present moment rather than memories. That is to say, once a known end-of-the-world creature is detected, it should be censored, unless of course someone was there to see it, in which case they should be given the option to remember it under the condition that we know who they are, and can prevent it. All in a distributed ownership system where the new entry-members begin with the first layer of consensus allowance (voting power), to regulate the safety of the network from hacks.

 

That is to say, a single device that you can only use if you submit to tracking if at the very least the code you write, in order for it to be debugged and ensure the safety of the network in the case that there exists known bugs and viruses that have not yet been isolated, or removed, or cured. If any user finds a bug or virus or hack, they are now given the opportunity to know all similar bugs, viruses and hacks on the same entry-level on the condition that they work to prevent it. This can happen on other layers of increasing severity.

How this would occur is about the time that brain-computer-interfaces are the norm for computer use, a person will then simply to be able to control the computer as fast as they can think, and then it's onto improving that speed. On the current devices they use the EFI mechanism to control and view us, but even they do not know all the dangerous code that can exist, nor do they automate the implementation of it's prevention, and nor do they share that information with us.

With a distributed system, it would be a matter of teaching yourself how to code, and learning the cryptocurrency that pays for the distributed-OS, then learn the distributed-OS and come up with a bug, enter into a private job detecting bugs, slowly improve until the member finishes the job and either prevents all forms of all bugs and viruses and free-roaming AI. A hierarchy built from competency rather than dominancy.

 

To detect all users 1:1 regardless of the device they use, a brain-computer-interface can use recorded electromagnetic signals and run it through an AI and pattern recognise the unique "snowflake"-like identity of each person's Wavelet Transformations (wavelets are different to waves, because a wave travels from a starting point to an ending point, whereas a Wavelet appears in general area and then dissipates, or travels out in all directions, equalising), and combine it with the derivative measures of the brain signals to detect the current state, and the changes to it, in as many ways as a pattern can recognise. Pure AI is not as powerful as combining it with a Derivative AND a Wavelet Transformation.

 

When we look at the AI playground it becomes clear that performing transformations on the data beforehand can help to convert it into the image we need to accurately predict things from it. Predicting a person's identity will be not unlike the baseline resonance of the electromagnetic waves in the skull and brain, which should come out as a series of wavelets, as that is how sound resonates in air and through it's solid container, just as electromagnetic waves through a salty electrically active fluid like the brain, and it's skull container. There need be more than one of the infinite Wavelet Transformations to enhance the activity of a standard AI, otherwise a very powerful AI would be needed from either much computing power or a very large dataset of brain signals. Perhaps on the order of 1 wavelet transformation per person, something much greater than I have the computing power for. It's actually from the messiest of signals that we can create the cleanest of data streams with AI, because it's like creating vectors of image transformations. Without the messy signal, the AI must first mess it up and then converge approximate it to find anything, if we mess it with a wavelet transformation, it skips the process and allows an easier converge approximate.

Ideally, we'd have combinatorials of major messy functions, like the Derivative, with the Wavelet, with the Wavelet Derivative, with the Derivative Wavelet. Integrals are useless, because they are cumulative rather than messy. A Fourier Transformation, standard frequencies might still pay the bills, but until I work out how to put imaginary numbers through an AI, I'll leave that for later, and judging by the data one gets out of it, it's pretty regular and noisy with not a lot that theoretically predicts identity, seeing as the data varies so much, one would at least need a Short Wave Fourier Transformation, and all that does is increase the resolution over increasing levels of Frequencies, but a Wavelet Transformation does so to an even greater degree.

 

At the moment I'm using a database of 64 channel EEGs with 25 recordings (very low), 256 Hz and 1 second recording (very low), for 122 layer neural networks, and 120 people to identify from. These are all variables subject to change, and inspection. Looking at all 64 channels being used in a higher dimensional AI would be interesting, looking at all transformations being used in a higher dimensional AI would also be interesting, looking at different neural networks would be interesting.

So far, the maximum accuracy I've had is 7% to identify someone from a group of 120, so my calculations come out to it taking approximately getting to 100% by around 2040 for the whole population, with a feasible cost of calculating it and getting an answer back in under a second, such that all users are identified, like a Driver's License, but a Computing License.

Essentially, all software engineers would recognise it's safety and security and move over to working on it, thus it would become the OS with the most Development, and then also the most functionality. Thereby being the most valuable cryptocurrency, while also preventing the end-of-the-world, and creating democracy and equal opportunity for all, on a competency hierarchy rather than a dominancy hierarchy. Except for the capitalist nature of the system... the dominancy hierarchy must be removed by creating a universal basic income, and that can only be done when all users are identifiably unique.

Which brings us back in full circle to the Snowflake Situation.

So we are special snowflakes. Wait, that's not my conclusion, that's my premise. And snowflakes cause ice ages, not just avalanches. The avalanche could've been the end of the world, but the ice age will be here first, which is cryptocurrency and universal basic income, rolled into one through the identity of a snowflake, of a user, that can undergo crystallisation and compression.

So if singularity, no, not end of the world.

And no, it's not the end of privacy, because the cryptocurrency that solves everything will be created by the demand of the consumer.